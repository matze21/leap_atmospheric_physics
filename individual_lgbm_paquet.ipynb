{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#dask.config.set({\"distributed.utils.perf.gc-fraction\": 0.8})\n",
    "#dask.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "# Get the number of available CPU cores\n",
    "n_cores = 1\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=1, threads_per_worker=1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numPartitions = data.npartitions\n",
    "#splitPart = int(numPartitions*0.7)\n",
    "#train = data.partitions[0:splitPart]\n",
    "#test = data.partitions[splitPart:numPartitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat60 = ['state_t', 'state_q0001','state_q0002','state_q0003','state_u','state_v','pbuf_ozone','pbuf_CH4','pbuf_N2O']\n",
    "\n",
    "#feat60 = ['state_q0001','state_q0002','state_q0003','state_u','state_v','pbuf_ozone','pbuf_CH4','pbuf_N2O']\n",
    "feat1 = ['state_ps','pbuf_SOLIN','pbuf_LHFLX','pbuf_SHFLX','pbuf_TAUX','pbuf_TAUY','pbuf_COSZRS','cam_in_ALDIF','cam_in_ALDIR','cam_in_ASDIF','cam_in_ASDIR','cam_in_LWUP','cam_in_ICEFRAC','cam_in_LANDFRAC','cam_in_OCNFRAC','cam_in_SNOWHLAND']\n",
    "\n",
    "target60 = ['ptend_t','ptend_q0001','ptend_q0002','ptend_q0003','ptend_u','ptend_v']\n",
    "target1 = ['cam_out_NETSW','cam_out_FLWDS','cam_out_PRECSC','cam_out_PRECC','cam_out_SOLS','cam_out_SOLL','cam_out_SOLSD','cam_out_SOLLD']\n",
    "\n",
    "features60 = [] \n",
    "for f in feat60:\n",
    "    features60 = features60 + [f+'_'+str(i) for i in range(60)]\n",
    "allF = features60 + feat1\n",
    "\n",
    "targets60 = [] \n",
    "for f in target60:\n",
    "    targets60 = targets60 + [f+'_'+str(i) for i in range(60)]\n",
    "allT = targets60 + target1\n",
    "\n",
    "targetsToDrop12 = [ 'ptend_q0001', 'ptend_q0002', 'ptend_q0003', 'ptend_u', 'ptend_v']\n",
    "dropT = ['ptend_q0002_12','ptend_q0002_13','ptend_q0002_14'] # attention, I think i also need to predict _15\n",
    "for f in targetsToDrop12:\n",
    "    dropT = dropT + [f+'_'+str(i) for i in range(12)]\n",
    "\n",
    "allT2 = [i for i in allT if i not in dropT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find corrupt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Optionally, start a Dask client for better error handling and performance\n",
    "client = Client()\n",
    "\n",
    "def find_parquet_files(folder):\n",
    "    \"\"\"Recursively find all parquet files in a given folder.\"\"\"\n",
    "    parquet_files = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".parquet\"):\n",
    "                parquet_files.append(os.path.join(root, file))\n",
    "    return parquet_files\n",
    "\n",
    "# Collect all Parquet files from all folders\n",
    "all_parquet_files = []\n",
    "all_parquet_files.extend(find_parquet_files(folders[3]))\n",
    "\n",
    "corrupted_files = []\n",
    "\n",
    "# Attempt to read each Parquet file individually\n",
    "for file in all_parquet_files:\n",
    "    try:\n",
    "        df = dd.read_parquet(file)\n",
    "        # Force computation to check for any reading issues\n",
    "        df.head()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "        corrupted_files.append(file)\n",
    "\n",
    "if corrupted_files:\n",
    "    print(\"The following files are corrupted or not Parquet files:\")\n",
    "    for corrupted_file in corrupted_files:\n",
    "        print(corrupted_file)\n",
    "else:\n",
    "    print(\"No corrupted files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corrupted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for file in corrupted_files:\n",
    "    os.remove(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"distributed.utils_perf\").setLevel(logging.ERROR)\n",
    "data['ptend_q0002_15'].compute().hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize data\n",
    "- all variables seem to be somewhat stationary -> no time dependency in data\n",
    "- we can just downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHistPlt(a, f,st):\n",
    "        #if not os.path.exists('histplots/'+f+st+'.jpg'):\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))   \n",
    "\n",
    "        # Histogram\n",
    "        ax1.hist(a, bins=100, edgecolor='k', alpha=0.7)\n",
    "        #ax1.set_xlabel(f)\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Histogram of '+f)    \n",
    "\n",
    "        # Time Series\n",
    "        ax2.scatter(a.index, a[f], s=1, alpha=0.7)\n",
    "        ax2.set_xlabel('index')\n",
    "        ax2.set_ylabel(f)\n",
    "        m = a.mean()\n",
    "        s = a.std()\n",
    "        ax2.set_title('mean'+str(round(m,2)) + ' std '+str(round(s,2)))\n",
    "\n",
    "        # Adjust layout\n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "        #fig.savefig('histplots/'+f+st+'.jpg')\n",
    "        #else:\n",
    "        #print('skipped',f)\n",
    "def createHist(a,f,st):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))   \n",
    "    ax1.hist(a, bins=100, edgecolor='k', alpha=0.7)\n",
    "    #ax1.set_xlabel(f)\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Histogram of '+f)  \n",
    "    m = a.mean()\n",
    "    s = a.std()\n",
    "    b = (a - a.mean())/a.std()\n",
    "    ax2.hist(a, bins=100, edgecolor='k', alpha=0.7)\n",
    "    ax2.set_xlabel(f)\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.set_title('mean'+str(round(m,2)) + ' std '+str(round(s,2)))\n",
    "    fig.savefig('histplots/'+f+st+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature: distribution moves from left to right\n",
    "for f in allF:\n",
    "    if not os.path.exists('histplots/'+f+'feat'+'.jpg'):\n",
    "        a = data[f].compute().reset_index()\n",
    "        createHistPlt(a,f, 'feat')\n",
    "for f in allT2:\n",
    "    if not os.path.exists('histplots/'+f+'targ'+'.jpg'):\n",
    "        a = data[f].compute().reset_index()\n",
    "        createHistPlt(a,f, 'targ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "a = data[f].compute().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (data['ptend_q0002_26']*1200+data['state_q0001_26']).compute().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(a[f])-min(a[f]), max(a[f]), min(a[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a[f]-min(a[f])) /(max(a[f])-min(a[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[f]\n",
    "#a.loc[a[f]>-1e-11][f]\n",
    "b = a.copy()\n",
    "b[f] = -a[f]*1e10 #(a[f]-min(a[f])) /(max(a[f])-min(a[f]))\n",
    "#b[f] = np.exp(b[f])\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12, 8))   \n",
    "bins = ax1.hist(s[0], bins=1000, edgecolor='k', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a\n",
    "#[f] = np.log(1+a[f]) / np.log(1+max(a[f]))\n",
    "b[f] = a[f]/min(a[f])\n",
    "createHistPlt(b,f, 'targ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(a.sample(frac=0.5), x=f,histfunc='avg')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downsample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "orig_partitions = [i for i in range(0,int(data.npartitions))]\n",
    "np.random.shuffle(orig_partitions) #shuffles inplace\n",
    "\n",
    "trainSep = int(0.1* data.npartitions)\n",
    "valEnd = int(0.015* data.npartitions) + trainSep\n",
    "\n",
    "sampledPartIdxTrain = orig_partitions[0:trainSep]\n",
    "sampledPartIdxTest  = orig_partitions[trainSep:valEnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampledPartIdxTest), len(sampledPartIdxTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "size_in_bytes = sys.getsizeof(X_val)\n",
    "print('in mb',size_in_bytes/1000/1000) \n",
    "#del a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline approach (LGBM)\n",
    "- 0.45 public score (without temp data & not shuffled between train/test)\n",
    "- 0.47 public score (with temp data & shuffled properly 2*100 partitions)\n",
    "- room for more improvement  (feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertData(partIdStart, partIdEnd, train, featuresTrain, targetFeatures, mean_values, std_values):\n",
    "    X = train[featuresTrain].partitions[partIdStart:partIdEnd].compute()\n",
    "    y = train[targetFeatures].partitions[partIdStart:partIdEnd].compute()\n",
    "    # normalize\n",
    "    for f in featuresTrain:\n",
    "        X[f] = (X[f] - mean_values[f]) / std_values[f]\n",
    "    for f in targetFeatures:\n",
    "        y[f] = (y[f] - mean_values[f]) / std_values[f]\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def convertDataBack(y, pred, feature, mean_values, std_values):\n",
    "    cy = y*std_values[feature] + mean_values[feature]\n",
    "    cpred = pred*std_values[feature] + mean_values[feature]\n",
    "    return cy, cpred\n",
    "\n",
    "def calcR2scoreFromConvData(y, pred, feature, mean_values, std_values):\n",
    "    cy, cpred = convertDataBack(y, pred, feature, mean_values, std_values)\n",
    "    return r2_score(cy, cpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 partitions = 260mb\n",
    "import pandas as pd\n",
    "valList = []\n",
    "for i in sampledPartIdxTest:\n",
    "    valList.append(data.get_partition(int(i)).compute())\n",
    "val = pd.concat(valList)\n",
    "X_val = val[allF]\n",
    "y_val = val[allT2]\n",
    "del val, valList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'num_leaves': 15,\n",
    "    #'learning_rate': 0.05,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "r2ScoreDict = {}\n",
    "r2ScoreDict = {f: {} for f in allT2}\n",
    "\n",
    "partPerLoop = 100\n",
    "nsplitData = int(len(sampledPartIdxTrain)/partPerLoop)\n",
    "for i in range(nsplitData):\n",
    "    startPartIdx = i*partPerLoop\n",
    "    dlist = []\n",
    "    for j in range(partPerLoop):\n",
    "        dlist.append(data.get_partition(int(sampledPartIdxTrain[startPartIdx+j])).compute())\n",
    "    locdata = pd.concat(dlist)\n",
    "    print('done preprocessing data')\n",
    "    X = locdata[allF]\n",
    "\n",
    "    for f in allT2:\n",
    "        print('processing ',f)\n",
    "        fileName = 'individualLGBMs/model_'+f+'.txt'\n",
    "        gbm = lgb.Booster(model_file=fileName) if i != 0 else None\n",
    "\n",
    "        valSet = lgb.Dataset(X_val, label=y_val[f], free_raw_data=False)\n",
    "        y = locdata[f]\n",
    "        train_set = lgb.Dataset(X, y, free_raw_data=False)\n",
    "        gbm = lgb.train(params,\n",
    "                    train_set,\n",
    "                    num_boost_round=20, \n",
    "                    valid_sets=valSet,\n",
    "                    init_model=gbm)\n",
    "        \n",
    "        predTrain = gbm.predict(X)\n",
    "        predVal = gbm.predict(X_val)\n",
    "        r2train =r2_score(train_set.label, predTrain)\n",
    "        r2test =r2_score(valSet.label, predVal)\n",
    "        r2ScoreDict[f][i] = {'train':r2train,'test':r2test}\n",
    "        print('r2 scores', r2train,r2test)\n",
    "\n",
    "        gbm.save_model(fileName)\n",
    "        gbm.save_model('individualLGBMs/checkpoints/model_'+f+'_'+str(i)+'_'+str(round(r2test,3))+'.txt')\n",
    "        del y, train_set, valSet#, predTrain, predVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, locdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in allT2:\n",
    "    diff = r2ScoreDict[f][1]['test'] - r2ScoreDict[f][0]['test']\n",
    "    if diff < 0:\n",
    "        print(f,r2ScoreDict[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('individualLGBMs/r2ScoreDict.p', 'wb') as fp:\n",
    "    pickle.dump(r2ScoreDict, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more validation testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in allT2:\n",
    "    print('processing ',f)\n",
    "    fileName = 'individualLGBMs/model_'+f+'.txt'\n",
    "    gbm = lgb.Booster(model_file=fileName) if i != 0 else None\n",
    "    predVal = gbm.predict(X_val)\n",
    "    \n",
    "    r2test =r2_score(y_val[f], predVal)\n",
    "    r2ScoreDict[f][2] = {'test':r2test}\n",
    "    print('r2 scores', r2test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = dd.read_parquet(\"test\")\n",
    "sampleSubmissions = dd.read_parquet('sampleSub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "testList = []\n",
    "for i in range(testData.npartitions):\n",
    "    testList.append(testData.get_partition(int(i)).compute())\n",
    "test = pd.concat(testList)\n",
    "X_test = test[allF]\n",
    "\n",
    "sampSubList = []\n",
    "for i in range(sampleSubmissions.npartitions):\n",
    "    sampSubList.append(sampleSubmissions.get_partition(int(i)).compute())\n",
    "sampleSub = pd.concat(sampSubList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in allT2:\n",
    "    print('processing ',f)\n",
    "    fileName = 'individualLGBMs/model_'+f+'.txt'\n",
    "    gbm = lgb.Booster(model_file=fileName)\n",
    "    predVal = gbm.predict(X_test)\n",
    "    \n",
    "    sampleSub[f] = sampleSub[f] * predVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSub.to_parquet('sample_sub_LGBM_baseline2_shuff_allTrainF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sampleSub, testData,sampleSubmissions, X_test, sampSubList, testList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('leap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d127f3b59cdcbede3105ef79393826088284249e767f609c5a6124df566c40a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
