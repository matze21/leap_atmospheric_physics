{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "import sys\n",
    "import pickle \n",
    "\n",
    "from data_helpers import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meanDict_allT.pkl', 'rb') as f:\n",
    "    meanDict = pickle.load(f)\n",
    "\n",
    "with open('stdDict_allT.pkl', 'rb') as f:\n",
    "    stdDict = pickle.load(f)\n",
    "\n",
    "with open('minVal_allT2.pkl', 'rb') as f:\n",
    "    minDict = pickle.load(f)\n",
    "\n",
    "with open('zScore_allT2.pkl', 'rb') as f:\n",
    "    zscoreDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(seq1, transf1, f1):\n",
    "    df = pd.DataFrame(seq1)\n",
    "    df['transf'] = transf1\n",
    "    \n",
    "    #a = df.sort_values(by=f1).iloc[0:10000]\n",
    "    a = df.sample(n=1000000)\n",
    "    \n",
    "    \"\"\" in feature space \"\"\"\n",
    "    plt.scatter(x=range(a.shape[0]),y=a[f1], s=1,label=f1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \"\"\" in transformed space \"\"\"\n",
    "    plt.scatter(x=range(a.shape[0]),y=a['transf'], s=1,label='transformed')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "custom log function to map into a continuous region, gives more resolution to the small values\n",
    "\"\"\"\n",
    "def custom_log_2(x, minValue, offset=6, nullValFactor=0.99):  #offset of works for [-403:403] of x values otherwise sign is lost\n",
    "    nullValueFeat = -minValue*nullValFactor             # define the 0-value in the feature space\n",
    "    x[x==0] = nullValueFeat                             # will make problems bc 0 could be positive but also negative! dynamics will point in different directions\n",
    "    #plt.scatter(x=range(x.shape[0]),y=x, s=1,label='replace 0')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    y = np.log(abs(x))\n",
    "    #plt.scatter(x=range(x.shape[0]),y=y, s=1,label='log transf')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    y = y - offset                                      #move curve down such that we have a bigger domain that always has negative values as an outcome [-403:403]\n",
    "    #plt.scatter(x=range(x.shape[0]),y=y, s=1,label='offset')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    nullValueLog = np.log(abs(nullValueFeat)) - offset  # transform 0-value into log space\n",
    "    y[x>0] = nullValueLog - (y[x>0] - nullValueLog)\n",
    "    #plt.scatter(x=range(x.shape[0]),y=y, s=1,label='mapping of pos values')\n",
    "    #plt.legend()\n",
    "    #plt.show()\n",
    "    return y\n",
    "\n",
    "\"\"\"\n",
    "inverse custom log function to map into a continuous region, gives more resolution to the small values\n",
    "\"\"\"\n",
    "def inv_custom_log_2(y,minValue, offset=6, nullValFactor=0.99):\n",
    "    nullValueFeat = -minValue*nullValFactor\n",
    "    nullValueLog  = np.log(abs(nullValueFeat)) - offset \n",
    "\n",
    "    x = y.copy()\n",
    "    x[y<nullValueLog] = nullValueLog - (x[y<nullValueLog] - nullValueLog) # remap to log function\n",
    "    x = x + offset                                                        # add offset\n",
    "    x = np.exp(x)                                                         # apply exp funciton (all pos values aftewards)\n",
    "    x[x<nullValueFeat] = 0                                                # map to 0\n",
    "    x[y>nullValueLog] = -x[y>nullValueLog]                                # find negative values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.linspace(-2,2,4000)\n",
    "test_y = np.ones(test_x.shape)# np.log(abs(test_x))\n",
    "\n",
    "transf = custom_log_2(test_y, minValue=1e-10)\n",
    "inv_transf = inv_custom_log_2(transf, minValue=1e-10)\n",
    "\n",
    "plt.scatter(x=test_x,y=test_y, s=1,label='gt')\n",
    "plt.scatter(x=test_x,y=inv_transf, s=1,label='reverse transf')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x=test_x,y=transf, s=1,label='transf')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = seq1.sample(n=100000)\n",
    "transf = custom_log_2(sampled, minValue=minDict[f1]['min'])\n",
    "inv_transf = inv_custom_log_2(transf, minValue=minDict[f1]['min'])\n",
    "\n",
    "plt.scatter(x=range(sampled.shape[0]),y=sampled, s=1,label='gt')\n",
    "plt.scatter(x=range(sampled.shape[0]),y=inv_transf, s=1,label='reverse transf')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x=range(sampled.shape[0]),y=transf, s=1,label='transf')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 'ptend_q0002_26'\n",
    "seq1 = data[f1].compute()\n",
    "\n",
    "transf1 = custom_log(seq1, minValue=minDict[f1]['min'])\n",
    "\n",
    "render(seq1, transf1, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 'ptend_q0002_15'\n",
    "seq1 = data[f1].compute()\n",
    "\n",
    "transf1 = custom_log(seq1, minValue=minDict[f1]['min'])\n",
    "\n",
    "render(seq1, transf1, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 'ptend_u_25'\n",
    "seq1 = data[f1].compute()\n",
    "\n",
    "transf1 = custom_log(seq1, minValue=minDict[f1]['min'])\n",
    "\n",
    "render(seq1, transf1, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
