{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "import sys\n",
    "import pickle \n",
    "\n",
    "from data_helpers import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meanDict_allT.pkl', 'rb') as f:\n",
    "    meanDict = pickle.load(f)\n",
    "\n",
    "with open('stdDict_allT.pkl', 'rb') as f:\n",
    "    stdDict = pickle.load(f)\n",
    "\n",
    "with open('minVal_allT2.pkl', 'rb') as f:\n",
    "    minDict = pickle.load(f)\n",
    "\n",
    "with open('zScore_allT2.pkl', 'rb') as f:\n",
    "    zscoreDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "nStd = 3\n",
    "outliers1 = data.loc[((data[f]) > (meanDict[f]+ nStd*stdDict[f])) | ((data[f]) < (meanDict[f]- nStd*stdDict[f]))].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "outliers1['z_score'+'_'+f] = (outliers1[f] - meanDict[f]) / stdDict[f]\n",
    "outliers1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_55'\n",
    "nStd = 5\n",
    "n_outliers5 = data.loc[((data[f]) > (meanDict[f]+ nStd*stdDict[f])) | ((data[f]) < (meanDict[f]- nStd*stdDict[f]))].shape[0].compute()\n",
    "nStd = 3\n",
    "n_outliers3 = data.loc[((data[f]) > (meanDict[f]+ nStd*stdDict[f])) | ((data[f]) < (meanDict[f]- nStd*stdDict[f]))].shape[0].compute()\n",
    "n_data = data.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers3, n_outliers5, n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_55'\n",
    "nStd = 5\n",
    "outliers2 = data.loc[((data[f]) > (meanDict[f]+ nStd*stdDict[f])) | ((data[f]) < (meanDict[f]- nStd*stdDict[f]))].compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calc z score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    data = dd.read_parquet(folder)\n",
    "\n",
    "    for f in ['ptend_q0002_25']:\n",
    "        data['zscore_'+f] = (data[f] - meanDict[f])/stdDict[f]\n",
    "    \n",
    "    data.to_parquet(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check z dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zscore_ptend_q0002_55'].max().compute(),data['zscore_ptend_q0002_55'].min().compute(),data['zscore_ptend_q0002_26'].max().compute(),data['zscore_ptend_q0002_26'].min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zscore_ptend_q0002_25'].max().compute(),data['zscore_ptend_q0002_25'].min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['ptend_q0002_24']:\n",
    "    data['zscore_'+f] = (data[f] - meanDict[f])/stdDict[f]\n",
    "\n",
    "data['zscore_'+f].min().compute(),data['zscore_'+f].max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "outliers = data.loc[abs(data['zscore_'+f]) > 5].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zscore dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "data.loc[((data['zscore_'+f]) < 5) | ((data['zscore_'+f]) > 5)].shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zscoreDict = dict()\n",
    "for f in allT2:\n",
    "    if f not in zscoreDict.keys():\n",
    "        data['zscore_'+f] = (data[f] - meanDict[f])/stdDict[f]\n",
    "        zscoreDict[f] = {'min':data['zscore_'+f].min().compute(), 'max':data['zscore_'+f].max().compute()}\n",
    "        print(f, zscoreDict[f])\n",
    "    else:\n",
    "        print('skipped', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscoreDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('zScore_allT2.pkl', 'wb') as f:\n",
    "    pickle.dump(zscoreDict, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_55'\n",
    "outlier2 = data.loc[abs(data['zscore_'+f]) > 30].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
