{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat60 = ['state_t', 'state_q0001','state_q0002','state_q0003','state_u','state_v','pbuf_ozone','pbuf_CH4','pbuf_N2O']\n",
    "feat1 = ['state_ps','pbuf_SOLIN','pbuf_LHFLX','pbuf_SHFLX','pbuf_TAUX','pbuf_TAUY','pbuf_COSZRS','cam_in_ALDIF','cam_in_ALDIR','cam_in_ASDIF','cam_in_ASDIR','cam_in_LWUP','cam_in_ICEFRAC','cam_in_LANDFRAC','cam_in_OCNFRAC','cam_in_SNOWHLAND']\n",
    "\n",
    "target60 = ['ptend_t','ptend_q0001','ptend_q0002','ptend_q0003','ptend_u','ptend_v']\n",
    "target1 = ['cam_out_NETSW','cam_out_FLWDS','cam_out_PRECSC','cam_out_PRECC','cam_out_SOLS','cam_out_SOLL','cam_out_SOLSD','cam_out_SOLLD']\n",
    "\n",
    "features60 = [] \n",
    "for f in feat60:\n",
    "    features60 = features60 + [f+'_'+str(i) for i in range(60)]\n",
    "allF = features60 + feat1\n",
    "\n",
    "targets60 = [] \n",
    "for f in target60:\n",
    "    targets60 = targets60 + [f+'_'+str(i) for i in range(60)]\n",
    "allT = targets60 + target1\n",
    "\n",
    "targetsToDrop12 = [ 'ptend_q0001', 'ptend_q0002', 'ptend_q0003', 'ptend_u', 'ptend_v']\n",
    "dropT = ['ptend_q0002_12','ptend_q0002_13','ptend_q0002_14'] # attention, I think i also need to predict _15\n",
    "for f in targetsToDrop12:\n",
    "    dropT = dropT + [f+'_'+str(i) for i in range(12)]\n",
    "\n",
    "allT2 = [i for i in allT if i not in dropT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "orig_partitions = [i for i in range(0,int(data.npartitions))]\n",
    "np.random.shuffle(orig_partitions) #shuffles inplace\n",
    "\n",
    "trainSep = int(0.95* data.npartitions)\n",
    "valEnd = data.npartitions #int(0.05* data.npartitions) + trainSep\n",
    "\n",
    "sampledPartIdxTrain = orig_partitions[0:trainSep]\n",
    "sampledPartIdxTest  = orig_partitions[trainSep:valEnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n60Feat = len(feat60)\n",
    "n1dFeat = len(feat1)\n",
    "n60Targ = len(target60)\n",
    "n1dTarg = len(target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Concatenate,BatchNormalization, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def r2_scoretf(y_true, y_pred):\n",
    "    sum_squares_residuals = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "    sum_squares_total = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)), axis=0)\n",
    "    r2 = 1 - (sum_squares_residuals / sum_squares_total)\n",
    "    return r2 #tf.reduce_mean(r2)\n",
    "\n",
    "def r2_scoreTrain(y_true, y_pred):\n",
    "    sum_squares_residuals = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "    sum_squares_total = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)), axis=0)\n",
    "    r2 = (sum_squares_residuals / sum_squares_total) # alwaysPositive, the smaller the better\n",
    "    return tf.reduce_mean(r2)\n",
    "\n",
    "class RSquaredMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='r_squared', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total_sum_squares = None#self.add_weight(name='total_sum_squares', initializer='zeros', shape=shape)\n",
    "        self.residual_sum_squares = None#self.add_weight(name='residual_sum_squares', initializer='zeros', shape=shape)\n",
    "        self.num_samples = self.add_weight(name=\"num_samples\", initializer='zeros',dtype=tf.int32)\n",
    " \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, self._dtype)\n",
    "        y_pred = tf.cast(y_pred, self._dtype)\n",
    "        \n",
    "        sum_squares_residuals = tf.reduce_sum(tf.square(y_true - y_pred), axis=0)\n",
    "        sum_squares_total = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true, axis=0)), axis=0)\n",
    "        sum_squares_total = tf.where(tf.equal(sum_squares_total, 0.0), tf.ones_like(sum_squares_total), sum_squares_total)\n",
    "        \n",
    "        if self.total_sum_squares is None:\n",
    "            self.total_sum_squares = self.add_weight(name='total_sum_squares', initializer='zeros', shape=sum_squares_total.shape)\n",
    "            self.residual_sum_squares = self.add_weight(name='residual_sum_squares', initializer='zeros', shape=sum_squares_residuals.shape)\n",
    "\n",
    "        self.total_sum_squares.assign_add(sum_squares_total)\n",
    "        self.residual_sum_squares.assign_add(sum_squares_residuals)\n",
    "\n",
    "    def result(self):\n",
    "        r_squared = 1 - (self.residual_sum_squares / self.total_sum_squares)\n",
    "        r_squared = tf.where(tf.math.is_nan(r_squared), tf.ones_like(r_squared), r_squared)\n",
    "        return tf.reduce_mean(r_squared)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.total_sum_squares.assign(tf.zeros_like(self.total_sum_squares))\n",
    "        self.residual_sum_squares.assign(tf.zeros_like(self.residual_sum_squares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTensorData(data, partPerLoop, startPartIdx,sampledPartIdx):\n",
    "    X1d, X2d, y1d, y2d, X1dI, X2dI, y1dI,y2dI  = None, None, None, None, False, False, False, False\n",
    "    for j in range(partPerLoop):\n",
    "        a = data.get_partition(int(sampledPartIdx[startPartIdx+j])).compute()\n",
    "        b = np.reshape(a[features60], (a.shape[0], n60Feat, 60))\n",
    "        b = np.transpose(b, (0,2,1))\n",
    "        X2d = np.concatenate([X2d,b], axis=0) if X2dI else b\n",
    "        b = np.reshape(a[targets60], (a.shape[0], n60Targ, 60))\n",
    "        b = np.transpose(b, (0,2,1))\n",
    "        y2d = np.concatenate([y2d,b], axis=0) if y2dI else b\n",
    "        X1d = np.concatenate([X1d,a[feat1]], axis=0) if X1dI else a[feat1]\n",
    "        y1d = np.concatenate([y1d,a[target1]], axis=0) if y1dI else a[target1]\n",
    "        X1dI, X2dI, y1dI,y2dI = True, True, True, True\n",
    "    return X1d, X2d, y1d, y2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "partPerLoop = 60\n",
    "\n",
    "for i in range(1):\n",
    "    startPartIdx = i*partPerLoop\n",
    "    X1d_val, X2d_val, y1d_val, y2d_val = getTensorData(data, partPerLoop, startPartIdx, sampledPartIdxTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sequentially\n",
    "partPerLoop = 100\n",
    "\n",
    "for i in range(1):\n",
    "    startPartIdx = i*partPerLoop\n",
    "    X1d, X2d, y1d, y2d = getTensorData(data, partPerLoop, startPartIdx, sampledPartIdxTrain)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d positional encoding (feature & position)\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def positional_encoding_2d(seq_length, num_features, wave_length=10000):\n",
    "    positions = np.arange(seq_length)[:, np.newaxis]\n",
    "    features = np.arange(num_features)[np.newaxis, :]\n",
    "    divisors = np.exp(-2 * np.pi * features / wave_length)\n",
    "    pos_enc = positions * divisors\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)\n",
    "\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, sequence_length, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model #d_model or model depth = dimensionality of encoding vector\n",
    "    # no need for an embedding layer since my input is a time series and not a word token\n",
    "    #self.embedding = tf.keras.layers.Embedding(sequence_length, d_model, mask_zero=True) \n",
    "    \n",
    "    #self.pos_encoding = positional_encoding(length=sequence_length, depth=d_model)\n",
    "    self.pos_encoding = positional_encoding_2d(sequence_length, d_model)\n",
    "\n",
    "    #TODO implement an encoding for the store and family\n",
    "    #self.store_fam_encoding\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    #print('encoder x', x.shape)\n",
    "    length = tf.shape(x)[1]\n",
    "\n",
    "    #x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    #x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "    x = x + self.pos_encoding#[tf.newaxis, :length, :]\n",
    "    return x\n",
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    #print(x.shape)\n",
    "    #print(context.shape)\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "    #print(attn_output.shape)\n",
    "    \n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "# only connect sequence to past & not to future\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__(name='decoderlayer')\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, sequence_length,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__(name='decoder')\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(sequence_length=sequence_length,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for i in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__(name='encoderlayer')\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, sequence_length, dropout_rate=0.1):\n",
    "    super().__init__(name='encoder')\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        sequence_length=sequence_length, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, enc_dec_num_layers, input_seq_dim_enc, input_seq_dim_dec, num_heads, fully_connected_size,\n",
    "               input_sequence_len, output_sequence_len, dropout_rate=0.1):\n",
    "    super().__init__(name='transformerBase')\n",
    "    self.encoder = Encoder(num_layers=enc_dec_num_layers, d_model=input_seq_dim_enc,\n",
    "                           num_heads=num_heads, dff=fully_connected_size,\n",
    "                           sequence_length=input_sequence_len,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=enc_dec_num_layers, d_model=input_seq_dim_dec,\n",
    "                           num_heads=num_heads, dff=fully_connected_size,\n",
    "                           sequence_length=output_sequence_len,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(output_sequence_len, name='finallayer')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    \n",
    "    context, x  = inputs\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "\n",
    "    # needed if out inputs are not always the same length and the embedding only works for a part\n",
    "    #try:\n",
    "    #  # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "    #  # b/250038731\n",
    "    #  del logits._keras_mask\n",
    "    #except AttributeError:\n",
    "    #  pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end to end transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Input, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        print('d_model', d_model)\n",
    "        self.positional_encoding = self.get_positional_encoding(position, d_model)\n",
    "\n",
    "    \n",
    "    def get_positional_encoding(self, position, d_model):\n",
    "        print('d_model', d_model)\n",
    "        #angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        #angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        #angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        angle_rads = np.reshape(np.arange(position), (position,1)) / 60\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        #print(inputs + tf.tile(tf.expand_dims(self.positional_encoding[:, :tf.shape(inputs)[1], 0],axis=-1), [1,1,inputs.shape[2]]))\n",
    "        return inputs + tf.tile(tf.expand_dims(self.positional_encoding[:, :tf.shape(inputs)[1], 0],axis=-1), [1,1,tf.shape(inputs)[2]])\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "def build_transformer_model(input_dim2d, const_input_dim, seq_output_dim, const_output_dim, featureSpaceSeq=512, featureSpaceConst=16, num_heads=8, ff_dim=2048, max_len=60):\n",
    "    # Sequence input\n",
    "    seq_input = Input(shape=(max_len, input_dim2d))\n",
    "    const_input = Input(shape=(const_input_dim,))\n",
    "\n",
    "\n",
    "    # embeddings\n",
    "    seq_embedding = Dense(featureSpaceSeq)(seq_input)\n",
    "    print('seq_embedding',seq_embedding.shape)\n",
    "    # transform the 1d input values into sequences of 60 in order to represent the effect on each position of the const values\n",
    "    const_embedding = Dense(featureSpaceConst)(const_input)\n",
    "    print('const_embedding',const_embedding.shape)\n",
    "    repeated_const_input = tf.tile(tf.expand_dims(const_embedding, axis=1), [1, max_len, 1])\n",
    "    print('repeated_const_input',repeated_const_input.shape)\n",
    "    combined_input = Concatenate()([seq_embedding, repeated_const_input])\n",
    "    print('combined_input',combined_input.shape)\n",
    "\n",
    "    \n",
    "    # Positional encoding\n",
    "    d_model = featureSpaceSeq + featureSpaceConst\n",
    "    print('d_model', d_model)\n",
    "    positional_encoding = PositionalEncoding(max_len, d_model)\n",
    "    seq_positional_encoded = positional_encoding(combined_input)\n",
    "    print('seq_positional_encoded',seq_positional_encoded.shape)\n",
    "    \n",
    "    # Transformer encoder\n",
    "    transformer_block = TransformerBlock(d_model, num_heads, ff_dim)\n",
    "    encoder_output = transformer_block(seq_positional_encoded) # this is the reach feature space with d_model*60 sequences\n",
    "    print('encoder_output',encoder_output.shape)\n",
    "    \n",
    "    \n",
    "    # Head 1: Outputs a sequence of shape (60, 6)\n",
    "    seq_output = Dense(seq_output_dim, name='2d')(encoder_output)\n",
    "    print('seq_output',seq_output.shape)\n",
    "    \n",
    "    # Head 2: Outputs five constant target values\n",
    "    avg_pool = GlobalAveragePooling1D()(encoder_output)\n",
    "    print('avg_pool',avg_pool.shape)\n",
    "    combined = Concatenate()([avg_pool, const_input])\n",
    "    print('combined',combined.shape)\n",
    "    const_dense = Dense(d_model, activation='relu')(combined)\n",
    "    print('const_dense',const_dense.shape)\n",
    "    const_output = Dense(const_output_dim, name='1d')(const_dense)\n",
    "    print('const_output',const_output.shape)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=[seq_input, const_input], outputs=[seq_output])#, const_output])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "input_dim2d = n60Feat       # number of features in the input sequence\n",
    "const_input_dim = n1dFeat   # number of constant input features\n",
    "seq_output_dim = n60Targ    # number of features in the output sequence\n",
    "const_output_dim = n1dTarg  # number of constant output features\n",
    "max_len = 60\n",
    "featureSpaceSeq = 64\n",
    "featureSpaceConst = 16#2*n1dFeat\n",
    "ffDim = 128\n",
    "\n",
    "model = build_transformer_model(input_dim2d, const_input_dim, seq_output_dim, const_output_dim, max_len=max_len,featureSpaceSeq=featureSpaceSeq,featureSpaceConst=featureSpaceConst, ff_dim=ffDim)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[RSquaredMetric()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit([X2d, X1d], [y2d, y1d], epochs=1, batch_size=32, validation_data=([X2d_val, X1d_val],[y2d_val, y1d_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 feature space seq   \n",
    "#loss: 5.1093e-04 - r_squared: -4239921345867022336.0000 - val_loss: 3.2163e-07 - val_r_squared: -2053396349583360.0000\n",
    "# without embedding\n",
    "#loss: 6.1256e-04 - r_squared: -8781051153384210432.0000 - val_loss: 3.4702e-07 - val_r_squared: -874387024642048.0000\n",
    "# with embedding,  fspace=64,constf=16,ffdim=128\n",
    "#2.9717e-04 - r_squared: -4653134858015473664.0000 - val_loss: 1.1647e-07 - val_r_squared: -414988464291840.0000\n",
    "tf.random.set_seed(42)\n",
    "hist = model.fit([X2d, X1d], [y2d], epochs=5, batch_size=128, validation_data=([X2d_val, X1d_val],[y2d_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2d_pred = model.predict([X2d_val, X1d_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2d_pred0 = np.reshape(y2d_pred, (y2d_pred.shape[0],-1))\n",
    "y2d_val0 = np.reshape(y2d_val, (y2d_val.shape[0],-1))\n",
    "r2_scores = []\n",
    "f = np.reshape(np.reshape(np.array(targets60), (n60Targ,60)).transpose(), (1,-1))\n",
    "for i in range(y2d_val0.shape[1]):\n",
    "    r2 = r2_score(y2d_val0[:, i], y2d_pred0[:, i])\n",
    "    print(f[0][i], r2)\n",
    "    r2_scores.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(y2d_pred0, columns=f[0])\n",
    "b = pd.DataFrame(y2d_val0, columns=f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data looks odd\n",
    "a.ptend_t_0.plot()\n",
    "b.ptend_t_0.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 feature space \n",
    "# seq loss: 0.0012 - r_squared: -9318544663843438592.0000\n",
    "hist = model.fit([X2d, X1d], [y2d], epochs=1, batch_size=32, validation_data=([X2d_val, X1d_val],[y2d_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_encoding = PositionalEncoding(max_len, 512)\n",
    "inputs = np.ones((1, 60, 512))#.astype(np.float32)\n",
    "out = positional_encoding(inputs)\n",
    "out[0,0:3,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(60, 9))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_output, state_h, state_c = tf.keras.layers.LSTM(units=hidden_units, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, 6))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(units=hidden_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('leap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d127f3b59cdcbede3105ef79393826088284249e767f609c5a6124df566c40a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
