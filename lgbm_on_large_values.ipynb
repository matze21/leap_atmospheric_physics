{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "import sys\n",
    "import pickle \n",
    "\n",
    "from data_helpers import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "orig_partitions = [i for i in range(0,int(data.npartitions))]\n",
    "np.random.shuffle(orig_partitions) #shuffles inplace\n",
    "\n",
    "trainSep = int(0.7* data.npartitions)\n",
    "valEnd = data.npartitions #int(0.05* data.npartitions) + trainSep\n",
    "\n",
    "sampledPartIdxTrain = orig_partitions[0:trainSep]\n",
    "sampledPartIdxTest  = orig_partitions[trainSep:valEnd]\n",
    "\n",
    "with open('meanDict_allT.pkl', 'rb') as f:\n",
    "    meanDict = pickle.load(f)\n",
    "\n",
    "with open('stdDict_allT.pkl', 'rb') as f:\n",
    "    stdDict = pickle.load(f)\n",
    "\n",
    "with open('minVal_allT2.pkl', 'rb') as f:\n",
    "    minDict = pickle.load(f)\n",
    "\n",
    "with open('zScore_allT2.pkl', 'rb') as f:\n",
    "    zscoreDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTrain=[]\n",
    "nPartitions=30\n",
    "for i in range(int(nPartitions/5)):\n",
    "    baseTrain.append(data.partitions[sampledPartIdxTrain[i*5:i*5+5]].compute())\n",
    "baseTrain = pd.concat(baseTrain)\n",
    "\n",
    "baseVal=[]\n",
    "nPartitions=15\n",
    "for i in range(int(nPartitions/5)):\n",
    "    baseVal.append(data.partitions[sampledPartIdxTest[i*5:i*5+5]].compute())\n",
    "baseVal = pd.concat(baseVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeV = pd.read_parquet('large_training_df_0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = largeV.loc[abs(largeV[f]) > abs(meanDict[f])]\n",
    "sep = int(largeV.shape[0]*0.7)\n",
    "end = largeV.shape[0]-1\n",
    "train=pd.concat([baseTrain, largeV.iloc[0:sep]])\n",
    "val = pd.concat([baseVal, largeV.iloc[sep:end]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0001_17'\n",
    "f = 'ptend_q0002_26'\n",
    "f = 'ptend_q0002_55'\n",
    "\n",
    "filtered = largeV.loc[abs(largeV[f]) > abs(meanDict[f])]\n",
    "sep = int(filtered.shape[0]*0.7)\n",
    "end = filtered.shape[0]-1\n",
    "train=pd.concat([baseTrain, filtered])#.iloc[0:sep]])\n",
    "val = baseVal #pd.concat([baseVal, filtered.iloc[sep:end]])\n",
    "\n",
    "valSet = lgb.Dataset(val[allF], label=val[f], free_raw_data=False)\n",
    "train['weight'] = abs(train[f]-meanDict[f])\n",
    "trainSet = lgb.Dataset(train[allF], train[f])#, weight=train['weight']/train['weight'].min(),free_raw_data=False)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    #'num_leaves': 15,\n",
    "    #'learning_rate': 0.05,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "\n",
    "gbm = None\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "            trainSet,\n",
    "            num_boost_round=100, \n",
    "            valid_sets=valSet,\n",
    "            #callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=True)],\n",
    "            init_model=gbm)\n",
    "\n",
    "predTrain = gbm.predict(train[allF])\n",
    "predVal = gbm.predict(val[allF])\n",
    "r2train =r2_score(train[f], predTrain)\n",
    "r2test =r2_score(val[f], predVal)\n",
    "print('r2 scores', r2train,r2test)# 'transormed',r2_score(train[transfF], predTrain0),r2_score(val[transfF], predVal0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=range(train.shape[0]),y=train[f], s=1,label=f)#\n",
    "plt.scatter(x=range(train.shape[0]),y=predTrain, s=1,label='pred_train')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x=range(val.shape[0]),y=val[f], s=1,label=f)\n",
    "plt.scatter(x=range(val.shape[0]),y=predVal, s=1,label='pred_test')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
