{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "import sys\n",
    "import pickle \n",
    "\n",
    "from data_helpers import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    #'train0_25',\n",
    "    #'train25_50',\n",
    "    'train50_75',\n",
    "    #'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "orig_partitions = [i for i in range(0,int(data.npartitions))]\n",
    "np.random.shuffle(orig_partitions) #shuffles inplace\n",
    "\n",
    "trainSep = int(0.95* data.npartitions)\n",
    "valEnd = data.npartitions #int(0.05* data.npartitions) + trainSep\n",
    "\n",
    "sampledPartIdxTrain = orig_partitions[0:trainSep]\n",
    "sampledPartIdxTest  = orig_partitions[trainSep:valEnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "partPerLoop = 35\n",
    "\n",
    "for i in range(1):\n",
    "    startPartIdx = i*partPerLoop\n",
    "    val, combinedF,transT = concatData(data, partPerLoop, startPartIdx, sampledPartIdxTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatSampledData(data, partPerLoop, startPartIdx,sampledPartIdx, f, mean, separator):\n",
    "    dfLarge = []\n",
    "    dfSmall = []\n",
    "    for j in range(partPerLoop):\n",
    "        a = data.get_partition(int(sampledPartIdx[startPartIdx+j])).compute()\n",
    "        a, newF = addFeatures(a)\n",
    "\n",
    "        tr_large = a.loc[abs(a[f]) > separator*abs(mean)]\n",
    "        tr_small = a.loc[abs(a[f]) < separator*abs(mean)]\n",
    "\n",
    "        tr_small = tr_small.sample(n=1000, random_state=42)\n",
    "\n",
    "        \n",
    "        dfLarge.append(tr_large)\n",
    "        dfSmall.append(tr_small)\n",
    "        allF = features60+newF+feat1\n",
    "    \n",
    "    return pd.concat(dfLarge), pd.concat(dfSmall), allF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training sequentially\n",
    "partPerLoop = len(sampledPartIdxTrain)\n",
    "\n",
    "f = 'ptend_q0002_26'\n",
    "mean_f = data[f].mean().compute()\n",
    "\n",
    "for i in range(1):\n",
    "    startPartIdx = i*partPerLoop\n",
    "    tr_large, tr_small, allF = concatSampledData(data, partPerLoop, startPartIdx, sampledPartIdxTrain, f, mean_f, separator=3)  # sep = 10 -> only like 20 large vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = data[f].std().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(tr_large)/1e6, sys.getsizeof(tr_small)/1e6 #in mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
