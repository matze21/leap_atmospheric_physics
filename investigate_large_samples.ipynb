{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "import dask_ml\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Sending large graph.*\")\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.multiprocessing\n",
    "\n",
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "import sys\n",
    "import pickle \n",
    "\n",
    "from data_helpers import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(processes=True,n_workers=6, threads_per_worker=1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "# Read Parquet files from each folder into Dask DataFrames\n",
    "dfs = [dd.read_parquet(folder) for folder in folders]\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptend_q002 = []\n",
    "for i in range(60):\n",
    "    ptend_q002.append('ptend_q0002_'+str(i))\n",
    "\n",
    "targetsToDrop12 = [ 'ptend_q0001', 'ptend_q0002', 'ptend_q0003', 'ptend_u', 'ptend_v']\n",
    "dropT = [] #'ptend_q0002_12','ptend_q0002_13','ptend_q0002_14'] # attention, I think i also need to predict _15\n",
    "for f in targetsToDrop12:\n",
    "    dropT = dropT + [f+'_'+str(i) for i in range(12)]\n",
    "\n",
    "allT2 = [i for i in allT if i not in dropT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean & stddev computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDict ={}\n",
    "for f in allT:\n",
    "    meanDict[f] = data[f].mean().compute()\n",
    "\n",
    "with open('meanDict_allT.pkl', 'wb') as f:\n",
    "    pickle.dump(meanDict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdDict ={}\n",
    "for f in allT:\n",
    "    stdDict[f] = data[f].std().compute()\n",
    "\n",
    "with open('stdDict_allT.pkl', 'wb') as f:\n",
    "    pickle.dump(stdDict, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDict ={}\n",
    "for f in allT:\n",
    "    maxDict[f] = abs(data[f]).max().compute()\n",
    "\n",
    "with open('maxDict_allT.pkl', 'wb') as f:\n",
    "    pickle.dump(maxDict, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('meanDict_allT.pkl', 'rb') as f:\n",
    "    meanDict = pickle.load(f)\n",
    "\n",
    "with open('stdDict_allT.pkl', 'rb') as f:\n",
    "    stdDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_squared_error(row, mean_values,std_values, columns):\n",
    "    return sum(((row[col] - mean_values[col])/std_values[col]) ** 2 for col in columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error_per_row = data.apply(lambda row: calculate_squared_error(row, meanDict, stdDict, allT2), axis=1, meta=('x', 'f8'))\n",
    "\n",
    "# Compute the result\n",
    "result = squared_error_per_row.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('sumSquaredError.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('sumSquaredError.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes = result['0']/max(result['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes = normRes.reset_index()#.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes.loc[normRes[0] > 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.assign(norm_weight = normRes[0].values)\n",
    "dask_series = dd.from_pandas(normRes, npartitions=data.npartitions)#,chunks=data.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "dask_array = da.from_array(normRes[0], chunks=data.partitions[0].shape[0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by assign function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(normRes), max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.assign(weight=data.apply(lambda row: calculate_squared_error(row, meanDict, stdDict, allT2), axis=1, meta=('x', 'f8')))\n",
    "data1['normWeight'] = data1['weight'] / max(result['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeSamp = data1.loc[(data1['normWeight'] > 0.0001)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largeSamp = largeSamp.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = dd.from_pandas(normRes, npartitions=data.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(new_index=new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('new_index', sorted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform df per partition and write it to source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_squared_error(row, mean_values,std_values, columns):\n",
    "    return sum(((row[col] - mean_values[col])/std_values[col]) ** 2 for col in columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    #'testPar',\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "def calculate_squared_errorPart(partition, mean_values, std_values, columns):\n",
    "    #return sum(((row[col] - mean_values[col])/std_values[col]) ** 2 for col in columns)\n",
    "    partition['weight'] = partition.apply(lambda row : calculate_squared_error(row, mean_values, std_values, columns),axis=1)\n",
    "    #partition['weight'] = 1\n",
    "    return partition\n",
    "\n",
    "for folder in folders:\n",
    "    data = dd.read_parquet(folder)\n",
    "\n",
    "    data = data.map_partitions(\n",
    "        calculate_squared_errorPart,\n",
    "        mean_values=meanDict,\n",
    "        std_values=stdDict,\n",
    "        columns=allT2,\n",
    "        #meta=('squared_error', 'float64')\n",
    "        )\n",
    "    \n",
    "    data.to_parquet(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxVal = data['weight'].max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    'testPar',\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "def calculate_norm_weight(partition, maxVal):\n",
    "    #return sum(((row[col] - mean_values[col])/std_values[col]) ** 2 for col in columns)\n",
    "    partition['norm_weight'] = partition['weight'] / maxVal\n",
    "    #partition['weight'] = 1\n",
    "    return partition\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    data = dd.read_parquet(folder)\n",
    "\n",
    "    data = data.map_partitions(\n",
    "        calculate_norm_weight,\n",
    "        maxVal = maxVal\n",
    "        )\n",
    "    \n",
    "    data.to_parquet(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\n",
    "    #'testPar',\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "def calculate_squared_errorPart(partition, mean_values, std_values, columns):\n",
    "    #return sum(((row[col] - mean_values[col])/std_values[col]) ** 2 for col in columns)\n",
    "    partition['weight_ptend_q0002_26'] = partition.apply(lambda row : calculate_squared_error(row, mean_values, std_values, columns),axis=1)\n",
    "    #partition['weight'] = 1\n",
    "    return partition\n",
    "\n",
    "for folder in folders:\n",
    "    data = dd.read_parquet(folder)\n",
    "\n",
    "    data = data.map_partitions(\n",
    "        calculate_squared_errorPart,\n",
    "        mean_values=meanDict,\n",
    "        std_values=stdDict,\n",
    "        columns=['ptend_q0002_26'],\n",
    "        #meta=('squared_error', 'float64')\n",
    "        )\n",
    "    \n",
    "    data.to_parquet(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get large values per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator=10\n",
    "condition = None\n",
    "subF = []\n",
    "for i in range(20,27):\n",
    "    f = 'ptend_q0002_' + str(i)\n",
    "    subF.append(f)\n",
    "    if condition is None:\n",
    "        condition = (abs(data[f]) > separator*abs(meanDict[f]))\n",
    "    else:\n",
    "        condition = condition | (abs(data[f]) > separator*abs(meanDict[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_large = data.loc[condition]\n",
    "tr_large = tr_large.compute()\n",
    "# 5.5 min for sep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "trShape = tr_large.shape[0]\n",
    "for f in subF:\n",
    "    count26 = tr_large.loc[abs(tr_large[f]) > a*abs(meanDict[f])].shape[0]\n",
    "    print(f, count26, round(count26/trShape, 2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_large.loc[(abs(tr_large['ptend_q0002_26']) > separator*abs(meanDict['ptend_q0002_26'])) | (abs(tr_large['ptend_q0002_25']) > separator*abs(meanDict['ptend_q0002_25']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator=3\n",
    "tr_large_25 = data.loc[(abs(data['ptend_q0002_25']) > separator*abs(meanDict['ptend_q0002_25']))]\n",
    "tr_large_25 = tr_large_25.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator=3\n",
    "tr_large_27 = data.loc[(abs(data['ptend_q0002_27']) > separator*abs(meanDict['ptend_q0002_27']))]\n",
    "tr_large_27 = tr_large_27.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=range(tr_large.shape[0]),y=tr_large['ptend_q0002_26'], s=1,label='ptend_q0002_26')\n",
    "plt.scatter(x=range(tr_large.shape[0]),y=tr_large['ptend_q0002_25'], s=1,label='ptend_q0002_25')\n",
    "plt.scatter(x=range(tr_large.shape[0]),y=tr_large['ptend_q0002_24'], s=1,label='ptend_q0002_24')\n",
    "plt.scatter(x=range(tr_large.shape[0]),y=tr_large['ptend_q0002_27'], s=1,label='ptend_q0002_27')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze norm weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_tr = [\n",
    "    'train0_25',\n",
    "    'train25_50',\n",
    "    'train50_75',\n",
    "]\n",
    "folders_te = [\n",
    "    'train75_100'\n",
    "]\n",
    "\n",
    "dfs = [dd.read_parquet(folder) for folder in folders_tr]\n",
    "train = dd.concat(dfs)\n",
    "\n",
    "dfs = [dd.read_parquet(folder) for folder in folders_te]\n",
    "test = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_tr = train.loc[train['norm_weight'] > 0.0001].compute()\n",
    "# 0.001 ~6min, 1250 samples\n",
    "# 0.0005 ~8.5min, 4166 samples (min weight = 13126)\n",
    "# 0.0001 ~11.5min, 90485 (min weight 2625) -> too many unimportant samples I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_tr.to_parquet('large_training_df_0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 100k small samples\n",
    "small_sample_size = train.shape[0].compute()\n",
    "small_tr = train.sample(frac=100000/small_sample_size).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tr.to_parquet('small_training_df_0001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze large values per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'ptend_q0002_26'\n",
    "large_tr = data.loc[abs(data[f]) > abs(meanDict[f])].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_tr.to_csv('large_ptend_q0002_26.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9322381.95034371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.weight_ptend_q0002_26.max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 08:55:41,460 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:49429 -> tcp://127.0.0.1:49417\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "OSError: [Errno 55] No buffer space available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 1783, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49429 remote=tcp://127.0.0.1:51632>: OSError: [Errno 55] No buffer space available\n",
      "2024-07-02 08:55:46,549 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:49429\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 230, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2863, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:51632 remote=tcp://127.0.0.1:49429>: Stream is closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.weight_ptend_q0002_26.compute().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 09:03:01,395 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:49418 -> tcp://127.0.0.1:49419\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "OSError: [Errno 55] No buffer space available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 1783, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49418 remote=tcp://127.0.0.1:49517>: OSError: [Errno 55] No buffer space available\n",
      "2024-07-02 09:03:01,397 - distributed.worker - ERROR - failed during get data with tcp://127.0.0.1:49426 -> tcp://127.0.0.1:49419\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 962, in _handle_write\n",
      "    num_bytes = self.write_to_fd(self._write_buffer.peek(size))\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/tornado/iostream.py\", line 1124, in write_to_fd\n",
      "    return self.socket.send(data)  # type: ignore\n",
      "OSError: [Errno 55] No buffer space available\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 1783, in get_data\n",
      "    response = await comm.read(deserializers=serializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 140, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:49426 remote=tcp://127.0.0.1:49503>: OSError: [Errno 55] No buffer space available\n",
      "2024-07-02 09:03:01,398 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:49418\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 230, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2863, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49517 remote=tcp://127.0.0.1:49418>: Stream is closed\n",
      "2024-07-02 09:03:01,408 - distributed.worker - ERROR - Worker stream died during communication: tcp://127.0.0.1:49426\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 230, in read\n",
      "    buffer = await read_bytes_rw(stream, buffer_nbytes)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 366, in read_bytes_rw\n",
      "    actual = await stream.read_into(chunk)  # type: ignore[arg-type]\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2059, in gather_dep\n",
      "    response = await get_data_from_worker(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/worker.py\", line 2863, in get_data_from_worker\n",
      "    response = await send_recv(\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/Users/matthiaskargl/anaconda3/envs/leap/lib/python3.10/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://127.0.0.1:49503 remote=tcp://127.0.0.1:49426>: Stream is closed\n"
     ]
    }
   ],
   "source": [
    "weighgs=data.weight_ptend_q0002_26.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00361029e+00, 1.31940788e+01, 2.20803153e+01, 7.08946422e+01,\n",
       "       9.29669019e+01, 2.28740412e+02, 2.37511352e+02, 2.91140111e+02,\n",
       "       5.72682107e+02, 1.00928723e+03, 3.13025223e+03, 4.32181508e+03,\n",
       "       4.52985582e+03, 5.90548817e+03, 3.45585893e+04, 6.92163560e+04,\n",
       "       7.02532766e+04, 1.08038709e+05, 4.66634471e+05])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(weighgs)[-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('leap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d127f3b59cdcbede3105ef79393826088284249e767f609c5a6124df566c40a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
